# 数据库
### 1. 数据库中的事务是什么，MySQL中是怎么实现的
数据库中的事务是一个不可分割的工作单元，它必须满足 ACID 特性（原子性、一致性、隔离性、持久性），保证一系列操作要么全部成功，要么全部失败，从而确保数据从一种一致状态安全地转换到另一种一致状态。
在 MySQL 中，这主要通过 InnoDB 存储引擎来实现：
其持久性依靠 redo log（重做日志，先写日志后写磁盘，保证 crash-safe）；
原子性和隔离性的核心是 undo log（回滚日志）和多版本并发控制（MVCC）（通过创建数据快照避免读写冲突）；
而一致性则通过前述机制（原子性、隔离性、持久性）的共同保障以及数据库本身的约束（如主键、外键）来实现。
___
### 2. MySQL事务的特性?
MySQL 事务必须具备 ACID 四大特性：原子性（Atomicity） 保证事务内的操作要么全部成功，要么全部失败回滚；一致性（Consistency） 确保事务执行后数据库从一个一致状态变换到另一个一致状态，遵循所有约束规则；隔离性（Isolation） 控制并发事务间的相互影响，防止数据混乱；持久性（Durability） 保证事务提交后对数据的修改永久保存，即使系统故障也不会丢失。这些特性共同保障了数据库操作的可靠性和安全性。
___
### 3. 数据库事务的隔离级别?解决了什么问题?默认事务隔离级别?
数据库事务的隔离级别（读未提交、读已提交、可重复读、串行化）定义了并发事务之间的可见性规则，主要用于解决多个事务同时执行时可能导致的脏读、不可重复读和幻读问题；MySQL 的 InnoDB 存储引擎默认隔离级别是可重复读（Repeatable Read），它通过 MVCC（多版本并发控制） 和 间隙锁（Gap Lock） 机制避免了脏读和不可重复读，并一定程度上解决了幻读问题。
___
### 4. 脏读，幻读，不可重复读的定义
脏读是指一个事务读到了另一个未提交事务修改的数据，若对方回滚则读到的是无效数据；不可重复读是指一个事务内两次读取同一行数据，结果不一致（ due to 其他事务修改了该行数据并提交）；幻读是指一个事务内两次按相同条件查询，检索到的行数不一致（ due to 其他事务新增或删除了符合条件的行并提交）。三者均是并发事务下数据读取的一致性问题和隔离性缺陷。

Innodb天然支持可重复读的隔离级别，解决了脏读和不可重复读的问题。

那么如何解决幻读呢，可以通过Gap lock间隙锁和记录锁Record lock，组成的Next-Key Lock：这是InnoDB实现间隙锁的方式。它是一个前开后闭区间 ((gap, record])，来阻止其他事务修改或者插入这个区间的数据。  

Next-key lock是加在索引上的，如果事务没有命中任何索引，那么就会命中全表，造成并发性降低。   

___
### 5. MySQL怎么实现可重复读?
MySQL 的可重复读（Repeatable Read） 隔离级别主要通过 多版本并发控制（MVCC） 机制实现：在事务启动时，InnoDB 会为该事务生成一个一致性读视图（ReadView），该视图决定了事务能看到哪个版本的数据；在事务执行期间，所有普通 SELECT 查询都会基于这个视图读取已经存在的旧数据版本（通过 undo log 构建），而非当前最新的数据，从而确保在同一事务内多次读取同一数据时，结果始终一致，避免了不可重复读问题。
<br><br>MVCC多版本并发控制：空间增长与负载相关：写操作越频繁（尤其是更新和删除），产生的旧版本数据就越多，UNDO LOG 体积增长越快。
但是占用是一时的，有定期的purge线程，它会定期清理那些不再被任何活跃事务需要的旧版本数据，从而回收空间。如果旧版本数据因为长事务的存在而无法被及时清理，才会导致空间过度膨胀，这才是需要避免的情况。

___
### 6. 数据库第三范式和第四范式区别?
数据库第三范式（3NF） 要求数据表中不存在非主键列对其它非主键列的传递依赖（即每个非主属性都直接依赖于主键），其核心是消除冗余数据；而第四范式（4NF） 在满足3NF的基础上，进一步要求消除多值依赖（即一个字段包含多个值，且这些值与其他字段存在独立关系），其核心是将多值属性分离到新表中，确保数据关系的原子性。简单来说，3NF解决数据冗余问题，4NF解决属性间一对多关系的结构问题。
<br>第一范式（1NF） 是数据库设计的基石，它要求表中的每个列（字段）都是原子的，即不可再分。<br>
第二范式（2NF） 在满足1NF的基础上，进一步要求表中的所有非主键字段必须完全依赖于整个主键，而不能只依赖于主键的一部分。<br>
第三范式（3NF） 在满足2NF的基础上，要求消除传递依赖，即任何非主键字段之间不能存在依赖关系，它们都必须只依赖于主键<br>
第四范式（4NF） 在满足3NF的基础上，处理更特殊的多值依赖问题。它要求一个表中不能存在两个或多个相互独立的多值属性。
___
### 7. MySQL的存储引擎?
MySQL 采用插件式存储引擎架构，其中 InnoDB 是默认且最核心的引擎，支持事务、行级锁、外键等关键特性，适用于绝大多数需要高并发和数据一致性的场景；MyISAM 是早期默认引擎，仅支持表级锁和全文索引，但不支持事务，适用于读多写少的静态数据查询；Memory 引擎将数据完全存储在内存中，速度极快但重启后数据丢失，适合临时表或缓存。此外，MySQL 还支持 Archive（高压缩比归档）、CSV（以文本文件存储）等专用引擎，用户可根据数据一致性、性能和应用场景需求灵活选择。
___
### 8. 数据库有哪些锁?
- 数据库锁按粒度可分为行级锁（锁定单行，并发高但开销大）、表级锁（锁定整表，开销小但并发低）和页级锁（折中方案）；
- 按操作类型可分为共享锁（S锁）（允许读禁止写）和排他锁（X锁）（禁止其他任何操作）；
- 按兼容性可分为乐观锁（通过版本号等机制避免冲突）和悲观锁（默认冲突发生，先加锁再操作）。
- 此外还有意向锁（快速判断表是否被加锁）、间隙锁（防止幻读）等特殊锁机制，共同保障并发事务的数据一致性。
___
### 9. 说下悲观锁、乐观锁
悲观锁是一种“先取锁，再访问” 的保守并发控制策略。它假定并发冲突很可能发生，因此在操作数据之前会先加锁（如行锁、表锁），确保在整个操作过程中数据不会被其他事务修改。这种机制通过数据库原生锁（如 SELECT ... FOR UPDATE）实现，保证了数据的强一致性，但会降低系统吞吐量，适用于写操作频繁、冲突概率高的场景。

乐观锁是一种“先访问，后检测” 的乐观并发控制策略。它假定并发冲突很少发生，因此不会直接加锁，而是在提交更新时检测数据是否被其他事务修改过。通常通过版本号（version）或时间戳字段实现：读取数据时记录版本号，更新时校验版本号是否变化，若变化则拒绝更新并抛出异常。这种机制通过应用程序逻辑实现，提高了系统吞吐量，但需要处理更新失败的重试逻辑，适用于读多写少、冲突概率低的场景。
___
### 10. 分布式数据库是什么?
分布式数据库是一种将数据存储、管理和处理分散在多个物理节点（计算机或服务器）上的数据库系统，这些节点通过网络连接协同工作，对外提供一个逻辑上的统一数据库视图；它通过数据分片（Sharding） 将大数据集水平拆分到不同节点，利用多副本（Replication） 机制实现高可用和容错，并通过分布式事务协议（如两阶段提交）保障跨节点数据的一致性，从而突破单机数据库在存储容量、处理性能和可靠性上的瓶颈，满足海量数据、高并发访问和全球化部署的业务需求。
___
### 11. 死锁产生的条件是什么?如何预防死锁?
死锁产生的四个必要条件是：

互斥条件（资源同一时间只能被一个进程占用）、请求与保持条件（进程在持有资源的同时请求新资源）、不可剥夺条件（资源只能由持有者主动释放）和循环等待条件（多个进程形成头尾相接的资源请求环）；

预防死锁的核心是破坏其中任意一个条件，具体方法包括：一次性申请所有资源（破坏请求与保持）、资源分层分配（破坏循环等待）、允许资源抢占（破坏不可剥夺）以及使用超时机制或死锁检测算法（如银行家算法）来主动避免或解除死锁状态。

**银行家算法**: 银行家算法是一种经典的死锁避免算法，由Edsger Dijkstra提出
。它通过在资源分配前进行安全性检查，确保系统始终处于安全状态，从而避免死锁
当一个进程提出资源请求时，算法会执行以下步骤：

1. 检查请求合法性：请求是否不超过其声明的最大需求（Need）且当前可用资源（Available）能够满足
。

2. 试探性分配：假设分配资源，并更新系统的状态（Available, Allocation, Need）
。

3. 安全性检查：检查试探分配后系统是否存在一个安全序列（即一个能让所有进程顺利执行完毕的顺序）。若存在，则正式分配；否则，请求将被拒绝，系统状态回滚
。

银行家算法虽然能有效避免死锁，但其局限性在于需要预先知道进程的最大资源需求，且算法本身有一定的开销
。

___
### 12. 介绍下数据库的ioin(内连接，外连接，全连接)，内连接和外连接(左，右连接)的区别
数据库连接（JOIN）用于合并多张表的记录，主要分为：内连接（INNER JOIN） 仅返回两表中匹配条件的记录；

外连接包括左外连接（LEFT JOIN）（返回左表全部记录及右表匹配记录，右表无匹配则补空）、右外连接（RIGHT JOIN）（返回右表全部记录及左表匹配记录，左表无匹配则补空）和全外连接（FULL JOIN）（返回左右表所有记录，无匹配均补空）；

核心区别在于内连接注重交集，而外连接保留单表或双表全部数据（左/右连接保留指定方向表的全部数据），适用于需展示主表完整信息及关联表可选信息的场景。
___
### 13. MySQL的join过程
MySQL 的 JOIN 过程核心是对多张表根据关联条件进行匹配和组合。其最基础且常用的算法是 Nested-Loop Join（嵌套循环连接），它通过双重循环实现：首先遍历驱动表（通常是小表或经过筛选的表）的每一行，然后对于每一行，遍历被驱动表的所有行并检查关联条件（如 ON t1.id = t2.id）是否满足，若满足则组合成结果集的一行。

为提升性能，MySQL 会利用索引来加速循环：理想情况下会在被驱动表的关联字段上建立索引，这样内层循环无需全表扫描，可快速定位匹配行，这种优化称为 Index Nested-Loop Join。若无可用索引，则需扫描整个被驱动表，效率低下，称为 Simple Nested-Loop Join。

对于大数据集，MySQL 可能采用更复杂的 Block Nested-Loop Join 算法：先将驱动表的多行读入连接缓冲区（Join Buffer），再批量与被驱动表比较，通过减少内层表的扫描次数来降低 I/O 开销。整个过程由优化器选择最高效的执行计划，确保联接操作性能最优
___
### 14. MySQL有哪些存储引擎?
MySQL 采用插件式存储引擎架构，其中 InnoDB 是默认且最核心的引擎，支持事务、行级锁、外键等关键特性，适用于绝大多数需要高并发和数据一致性的场景；MyISAM 是早期默认引擎，仅支持表级锁和全文索引，但不支持事务，适用于读多写少的静态数据查询；Memory 引擎将数据完全存储在内存中，速度极快但重启后数据丢失，适合临时表或缓存。此外，MySQL 还支持 Archive（高压缩比归档）、CSV（以文本文件存储）等专用引擎，用户可根据数据一致性、性能和应用场景需求灵活选择。
1. InnoDB：默认与核心引擎
InnoDB 是 MySQL 5.5 版本之后的默认存储引擎。它最重要的特点是提供了对事务（ACID）、行级锁和外键约束的完整支持。其设计目标就是处理大量短期事务和高并发读写负载，通过多版本并发控制（MVCC） 来实现非阻塞读和高并发性，是绝大多数需要数据完整性和高性能的应用的首选。

2. MyISAM：曾经的王者
MyISAM 是 MySQL 5.5 之前版本的默认引擎。它不支持事务和外键，只提供表级锁。其优势在于访问速度快，尤其适合执行大量的SELECT查询操作，并且支持全文索引（FULLTEXT）。但由于其锁的粒度大，在并发写操作多的情况下性能较差，且发生崩溃后数据恢复能力弱，现在已不推荐用于核心业务表。

3. Memory：极速的内存引擎
Memory 引擎（也称 HEAP）将所有数据都存储在内存中，因此读写速度极快。它通常用于充当临时表或缓存中间结果集，以加速查询。但其最大缺点是：服务器重启或崩溃后，所有数据都会丢失。并且它使用表级锁，只适用于低并发的临时场景。

4. 其他专用引擎
MySQL 还提供了一些针对特殊场景的引擎。例如：

Archive：仅支持插入和查询，不支持删除和更新。它会高密度压缩存储数据，非常适合存储日志、审计等归档数据。

CSV：它的表实际上是一个文本文件，以逗号分隔值格式存储数据，可以与 CSV 格式的文件直接交换数据，常用于数据交换和导入导出。

Blackhole：像“黑洞”一样，接受数据但不存储，任何写入的数据都会消失。主要用于复制架构中，将数据中继到从库。
___
### 15. 数据库中存储引擎MvlSAM与InnoDB的区别
MyISAM 与 InnoDB 的核心区别在于：MyISAM 不支持事务和外键，仅提供表级锁，访问速度快且支持全文索引，适用于读多写少的静态查询场景；而 InnoDB 支持事务、行级锁和外键约束，具备崩溃恢复能力，适用于需要高并发、数据一致性及事务支持的OLTP应用，是MySQL默认的存储引擎。
___
### 16. Mylsam适用于什么场景?
MyISAM 适用于读频率远高于写频率、且无事务要求的静态数据查询场景，例如数据仓库、日志分析、网页内容管理等读密集型应用，因其支持全文索引且访问速度快；但由于其仅提供表级锁且不支持事务，在高并发写入或需要数据强一致性的场景下性能较差且存在风险。
___
### 17. InnoDB和Mvlsam针对读写场景?
InnoDB 为高并发读写和事务安全场景设计（如电商、交易系统），而 MyISAM 仅适用于读远多于写且无事务要求的静态数据场景（如日志分析、内容管理）。
___
### 18. MySQL Innodb实现了哪个隔离级别?
MySQL InnoDB 存储引擎默认且完全实现了“可重复读（Repeatable Read）”隔离级别：它通过多版本并发控制（MVCC） 机制为每个事务创建一致性读视图（Read View），确保事务内多次读取同一数据时结果一致，避免了脏读和不可重复读；同时，通过间隙锁（Gap Lock） 和临键锁（Next-Key Lock） 的组合使用，有效防止了幻读现象，从而在标准 SQL 隔离级别基础上提供了更高级别的数据一致性保证。
___
### 19. InnoDB数据引擎的特点
InnoDB 是 MySQL 最核心、使用最广泛的存储引擎，其核心特点是：支持事务（ACID 特性）、使用行级锁实现高并发、支持外键约束以保证数据完整性，并通过 MVCC（多版本并发控制）实现非阻塞读，同时其采用聚簇索引组织数据，使得主键查询效率极高，是 MySQL 在需要可靠事务支持和高质量并发性能场景下的默认及首选引擎。

聚簇索引就是表本身，它决定了数据在磁盘上的物理排列顺序。它像一本字典的正文部分，内容（数据）本身就是按照拼音（主键）排序的。而二级索引则像字典前面的部首检字表，它自己按部首排序，但只告诉你某个字在正文的第几页（主键值），你需要根据这个页码再翻到正文才能看到这个字的详细解释（回表）。

___
### 20. InnoDB用什么索引
InnoDB 主要使用 B+Tree 索引，并且强制使用聚簇索引（Clustered Index）来组织存储表数据本身，同时所有普通索引（也称为二级索引 Secondary Index）也都是 B+Tree 结构，但其叶子节点存储的是主键值而非数据行。
___
## 21. Hash索引缺点
**无法进行范围查找：**
Hash 索引是基于哈希函数计算的，它将键值均匀地映射到不同的哈希桶中。它只关心键值是否相等，完全丧失了键值原有的顺序性。

**无法利用索引完成排序**

 **不支持部分索引键查询**： 哈希值是通过整个索引键计算出来的。如果你有一个复合 Hash 索引 on (col1, col2)，那么查询时必须提供 col1 和 col2 的完整值才能计算出哈希值进行查找。
对比B+Tree 支持的复合索引遵循最左前缀原则。对于索引 on (col1, col2, col3)，查询 WHERE col1 = 'A' 或 WHERE col1 = 'A' AND col2 = 'B' 都可以利用到这个索引。  

**哈希冲突问题**： 不同的键值通过哈希函数可能会计算出相同的哈希值，这就是哈希冲突。数据库必须要有方法处理冲突（比如在同一个哈希桶内用链表存放所有冲突的键值）。

___
### 22. 数据库索引的类型，各有什么优缺点?
 **B-Tree / B+Tree 索引**: 
这是最常用、最主流的索引类型。现在数据库（如MySQL/PostgreSQL）默认使用的都是其变种 B+Tree。
支持范围查询、支持最左前缀匹配，

**Hash 索引**
基于哈希表实现，只有精确匹配所有列的查询才有效

**全文索引**
专门用于搜索文本内容中的关键词，而不是直接比较是否相等。

**还有空间索引和位图索引**
___
### 23. MySQL的索引有哪些?索引如何优化?
索引优化是一门艺术，核心思想是：让查询尽可能快地找到所需数据，同时减少索引对写入操作和磁盘空间的负面影响。

**为合适的列创建索引**  
WHERE 子句的列：频繁作为查询条件的列。

JOIN 连接的列：用于表连接的列（外键）。

ORDER BY 和 GROUP BY 的列：索引本身有序，可以避免昂贵的文件排序（filesort）。

选择区分度高的列：索引列的值尽可能唯一。区分度 = count(distinct col) / count(*)，越高越好。例如，“性别”列区分度很低，建索引效果微乎其微。

使用前缀索引：对于很长的字符列（如 VARCHAR(255)），不需要对整个列建索引，可以只索引前一部分字符。关键是选择足够长的前缀以保证较高的区分度。

**复合索引（最左前缀原则）**
最左前缀原则：复合索引 (col1, col2, col3) 相当于同时创建了 (col1)、(col1, col2) 和 (col1, col2, col3) 三个索引。

优化策略：

将选择性最高的列放在左边（如果不需要范围查询）。

考虑查询频率：最常用的查询条件应该放在左边。

巧妙避免回表：创建覆盖索引，即索引包含查询所需要的所有字段。

**避免索引失效** 
隐式类型转换：索引列在查询条件中使用时，不要对其使用函数或表达式
```
-- 索引失效
SELECT * FROM users WHERE YEAR(create_time) = 2023;
-- 优化后（使用范围查询）
SELECT * FROM users WHERE create_time >= '2023-01-01' AND create_time < '2024-01-01';
```
LIKE '%abc%' 和 LIKE 'abc%'，前者会全局扫描，后者会范围扫描，比全表快。 

而且，不要对索引列进行运算，或者会导致索引失败。WHERE  id + 1 == 20 不如 id == 19.

OR条件如果前后都有索引，那无妨，如果任意一方无索引，都会导致全表扫描，  

**清理无用索引** 索引过多可能会导致insert、update等操作变慢，且会占用磁盘空间。   


___
### 24. 有哪些数据结构可以作为索引呢?

**B-Tree / B+Tree**  
简介：平衡多路搜索树。B+Tree 是 B-Tree 的变种，也是现代关系型数据库（如 MySQL/InnoDB, PostgreSQL）最常用、默认的索引数据结构。

B-Tree：每个节点既存储键（Key）也存储数据（Data指针或数据本身）。   
B+Tree：非叶子节点只存储键，不存储数据；所有数据都存储在叶子节点，且叶子节点之间通过指针相连，形成一个有序链表 。  
非常适合磁盘I/O：树形结构“矮胖”，减少了磁盘寻道次数（通常只需3-4次I/O就能在亿级数据中查找）。通用场景，尤其是需要范围查询、排序、模糊查询（前缀匹配）的情况。

**哈希表 (Hash Table)**

**跳表 (Skip List)**
一种在有序链表基础上添加了多级索引的随机化数据结构。  
通过构建多级索引（“express lanes”），实现类似二分查找的效果，从最高级索引开始，逐步向下缩小范围。
Redis 的 Sorted Set 底层就使用了跳表。在一些NoSQL数据库和内存系统中也有应用。

**倒排索引**
全文索引的核心数据结构。它不是“从文档到关键词”，而是“从关键词到文档”的映射。

适用场景：搜索引擎（Elasticsearch, Solr）、数据库的全文检索功能（MySQL的FULLTEXT索引）。

**Trie 树 (字典树)**
一种专门处理字符串序列的树形结构。每个节点代表一个字符，从根到节点的路径构成一个字符串前缀。  
通过公共前缀来减少不必要的字符串比较。

适用场景：搜索引擎的搜索建议、IP路由表、拼写检查。

___
### 25. B树与B+树的区别?
B树和B+树都是平衡多路搜索树， designed for disk-based storage systems. 它们的主要区别在于数据存储的方式和范围查询的效率。 

B树的节点既存放键（Key）也存放数据（Data）；而B+树的非叶子节点只存放键，数据只存放在叶子节点，且叶子节点之间通过指针相连形成链表。  

且B+树等值查询性能稳定，而B树可能在非叶子节点就命中了，快的话O（1），平均logn。 B+树范围查找的效率极高，而B树范围查找的效率就不高了,需要进行中序遍历，可能涉及多次不同层的磁盘I/O。 另外，B+树的非叶子节点只充当索引，不存数据。这就导致了，B+树空间利用率更高，层高更低。  

___
### 26. 为什么使用B+树作为索引结构?
之所以选择 B+树 作为索引结构，是因为它在磁盘I/O效率、查询性能和功能支持上达到了近乎完美的平衡，是专门为磁盘存储系统设计的“终极形态”。为了解决磁盘I/O瓶颈和高效支持范围查询这两个数据库最核心问题而精挑细选出的数据结构，是现代关系型数据库索引的事实标准。

**极致的磁盘I/O效率（最核心原因）**数据库数据量巨大，无法全部装入内存，性能瓶颈主要在于磁盘I/O（从磁盘读取数据到内存）。B+树 的设计完美契合了磁盘的工作特性。
“矮胖”的多路平衡树：B+树 的一个节点（对应一个磁盘页，如16KB）可以存储非常多的键（索引项）和指针。这意味着树的扇出（Fanout）很高，高度很低。

**无敌的范围查询性能**
这是 B+树 相对于 B树 和 Hash 索引的决定性优势，而范围查询是数据库最常用的操作之一（如BETWEEN, >, <, ORDER BY）。

**更高的空间利用率与查询稳定性**
非叶子节点纯索引：B+树 的非叶子节点不存储实际数据，只存储键（索引值）和指向子节点的指针。这使得每个非叶子节点能容纳更多的键，导致树更矮，I/O次数更少。
查询性能稳定：在 B+树 中，任何查询都必须从根节点走到叶子节点。因此，每次查询的路径长度（磁盘I/O次数）都是固定的 O(log n)，非常稳定。这有利于数据库优化器进行准确的代价评估。而 B树 的查询可能在内部节点就提前终止，性能不稳定。

**更优的全表扫描性能**
如果需要遍历整个表（如无WHERE条件的查询或数据分析），B+树 只需要简单地线性遍历最底层的叶子节点链表即可，这等价于高效的顺序磁盘读取。
而 B树 需要对整棵树进行中序遍历，效率低下。
___
### 27. 不使用B+树，可以用那个数据类型实现一个索引结构
哈希表、跳表、Trie、等




___
### 28. 介绍下MySQL的联合索引，联合索引使用原则
联合索引是指在一个表上，由多个列组合起来共同构成的一个索引。

```text
CREATE INDEX index_name ON table_name (column1, column2, column3, ...);
-- 示例：为 users 表的 last_name 和 first_name 创建联合索引
CREATE INDEX idx_name ON users (last_name, first_name);
```

想象一下电话簿。它并不是先按姓氏排序，再单独按名字排序；而是先按姓氏排序，在姓氏相同的情况下，再按名字排序。联合索引就是这样工作的。

**核心原则：最左前缀匹配原则**  
MySQL 在使用联合索引时，会从索引的最左边列开始，向右连续匹配，直到遇到范围查询（>, <, BETWEEN, LIKE）就停止匹配。


___
### 29. 数据库有必要建索引吗?
可以避免全表扫描，这是创建索引最主要的原因。对于 WHERE, JOIN, ORDER BY, GROUP BY 等操作，索引可以将时间复杂度从 O(n)（全表扫描）降低到 O(log n)（树形结构查找）。

加速表连接，
执行 JOIN 操作时，通常需要根据外键在另一张表中查找匹配的行。如果连接字段上有索引，这个查找过程会非常快。

避免排序（ORDER BY）和创建临时表（GROUP BY），
如果 ORDER BY 或 GROUP BY 的字段上有索引，并且顺序匹配，数据库可以直接按索引的顺序读取数据，避免昂贵的文件排序（filesort） 操作。

实现唯一性约束
主键（PRIMARY KEY）和唯一约束（UNIQUE KEY）本身就是一种特殊的索引。它们不仅能加速查询，还能保证数据的唯一性。

但是频繁写、频繁更新的表、不常用于查询的列，不建议使用索引。
___
### 30. MySQL缺点?
默认隔离级别与幻读：MySQL InnoDB 的默认隔离级别是 REPEATABLE-READ，并且声称通过间隙锁（Gap Lock）在这个级别避免了幻读。但这增加了锁的复杂性，在高并发下更容易引发死锁。而其他许多数据库（如 Oracle、PostgreSQL）的默认隔离级别是 READ-COMMITTED，被认为更简单且并发性能更好。

复制延迟问题：MySQL 的主从复制（Replication）是异步的（默认）。这意味着从库的数据可能落后于主库，从而产生延迟。虽然支持半同步复制，但也不是强一致的。这会导致应用程序可能读到旧数据，不适合对读写一致性要求极高的场景。

主要优势在于简单、可靠、高性能的 OLTP 事务处理，以及极其成熟的生态和社区。
___
### 31. 什么是脏读?怎么解决?
其他事务未提交的数据被读，然后该数据被回滚，则读到的就是脏数据。  

读已提交，可以利用MVCC来解决。
___
### 32. 为什么要有三大范式，建数据库时一定要遵循吗?
三大范式是数据库设计的黄金准则和理想目标，但在实际建库时，并不需要绝对遵循，有时甚至需要故意违反它以获得更好的性能。 

三大范式（1NF, 2NF, 3NF）的核心思想是：通过减少数据冗余来提升数据的完整性、一致性和可维护性。

有一个订单表(Order)和一个订单项表(OrderItems)，这是符合范式的。但要生成一张订单详情页，需要联表查询这两张表。如果订单量巨大，这个JOIN操作会非常慢。

数据仓库与OLAP系统

这类系统几乎都是反范式的。它们使用星型模型或雪花模型，其核心就是一个巨大的事实表（存储核心业务数据，如销售记录），周围围绕着一堆维度表（描述性数据，如时间、地点、产品）。事实表中存在大量外键和冗余数据，以避免在分析查询时进行复杂的多表关联。
___
### 33. 数据库一般对哪些列建立索引?索引的数据结构?
索引列选择：主键、外键、高频WHERE/ORDER BY/GROUP BY中的高选择性列。

数据结构：B+Tree 是关系型数据库索引的绝对主力，因为它完美地权衡了查询效率、功能支持和磁盘I/O。其他数据结构都是在特定场景下对它的补充。
___
### 34. MySOL中索引的建立需要考虑哪些问题
在为一个列或一组列创建索引前，先问自己这几个问题：

这个查询频繁吗？ （不频繁的查询不值得建）

这个列的选择性高吗？ （性别这种低选择性列不值得建）

这个索引会被用于 WHERE, ORDER BY, GROUP BY, JOIN 吗？ （明确索引的用途）

我是要建单列索引还是联合索引？ （联合索引要遵守最左前缀原则）

我能设计成覆盖索引吗？ （能覆盖则性能最佳）

表的写操作频率高吗？ （写操作多则要严格控制索引数量）

我验证过它的效果吗？ （必须用 EXPLAIN 验证）

遵循这些原则，你就能避免“乱建索引”，从而真正发挥索引的强大威力，而不是让它成为系统的包袱。


___
### 35. 关系型数据库与非关系型数据库区别
关系型数据库：像严谨的Excel表格，高度结构化，强调数据关系和一致性。

非关系型数据库：像各种不同的储物柜（衣柜、文件柜、货架），形态各异，强调灵活性和特定场景下的性能。

MySQL/PostgreSQL：存储核心数据，如用户账户、订单、支付信息，利用其强事务保证资金安全。

Redis：用作购物车、秒杀库存的缓存，利用其极快的内存读写速度。

MongoDB：存储商品信息、用户评论，利用其灵活的Schema便于迭代。

Elasticsearch：提供强大的商品搜索功能。

Neo4j：实现“购买此商品的用户也购买了”的图关系推荐。
___
### 36. MySQL与Redis区别
MySQL 是一个全面的关系型数据库管理系统。它的核心职责是“持久化、安全地存储数据”，并提供强大的查询（SQL）、事务（ACID）支持。它的数据 primarily 存储在磁盘上，保证数据不会因为断电或重启而丢失。

Redis 是一个基于内存的键值数据结构存储。它的核心职责是“提供极快的读写访问”和“实现灵活的数据结构功能”。内存是它的主战场，磁盘仅用于备份和恢复。

用Redis弥补MySQL性能上的不足，用MySQL为Redis提供数据持久化保障，是构建高性能Web应用的经典架构。
___
###  37. 列式数据库和行式数据库优劣比对
行式数据库和列式数据库的根本区别在于数据的物理存储方式，这种差异直接决定了它们各自的应用场景和优劣。  

列式数据库的优势 (也是行式数据库的劣势)分析查询（OLAP）性能极高

行式数据库的优势 (也是列式数据库的劣势)事务处理（OLTP）性能高

像 ClickHouse、Apache Druid、Amazon Redshift 这类分析型数据库，数据是按列存储的。把每一列的所有值紧密地存储在一起。读取一列数据非常快。

像 MySQL、PostgreSQL、Oracle 这类传统数据库，数据是按行存储的。把一行的所有列值紧密地存储在一起。读取一行数据非常快。
___
### 38. 除了UTF-8还有什么编码格式
首选 UTF-8：对于任何新项目、新系统、网站、API，毫无例外地应该使用 UTF-8 编码。它已经是互联网上的绝对主流和事实标准。 

___
### 39. 布隆过滤器的基本原理是什么？局限性是什么？使用什么方法可以增加删除的功能？
布隆过滤器（Bloom Filter）。这是一个非常巧妙且实用的数据结构，尤其在大数据和数据库领域应用广泛。 

布隆过滤器的核心是一个概率型数据结构，用于回答一个问题：“某个元素是否一定不在集合中，或者可能在集合中”。

它由两部分组成：   
- 一个很大的位数组（Bit Array）：初始时所有位都置为 0。
- 一组哈希函数（Hash Functions）：每个函数都能将输入的元素映射到位数组的一个位置上。

数据库：LevelDB/RocksDB 使用它来判断一个数据块中是否包含某个键，避免对磁盘进行不必要的访问。

它通过一个可接受的、可控的小概率误判，换来了巨大的空间和时间效率的提升。
___
### 40. 你在哪些场景下使用了布隆过滤器？
在 Redis、Memcached 等分布式缓存面前，布隆过滤器充当了“守门员”的角色。 

有效防止了缓存穿透攻击，保护了底层数据库。即使有1%的误判（布隆过滤器误以为不存在的键存在），也只是多了一次缓存查询，而不会压垮数据库。

判断一个邮件地址或密码是否在黑名单中。

如何使用：将所有黑名单中的条目（如垃圾邮件发件人地址、常见的弱密码）放入一个布隆过滤器。当新邮件到达或用户设置密码时，先用过滤器快速判断。


___
### 41. SQL慢查询的解决方案（优化）？
___
### 42. 聚簇索引、非聚簇索引说一下
聚簇索引决定了表中数据行的物理存储顺序。表的数据就存储在索引的叶子节点上。因为数据行本身只能按一种顺序物理存放，所以一张表有且只能有一个聚簇索引。
如果你定义了主键（PRIMARY KEY），InnoDB就会使用它作为聚簇索引。
如果没有主键，InnoDB会选择第一个所有列都非空的唯一索引（UNIQUE NOT NULL）作为聚簇索引。
对于主键的等值查询和范围查询速度极快，因为一旦找到索引就找到了数据，无需二次查找。 

非聚簇索引的数据存储顺序与索引顺序无关。它像一本独立的目录，索引结构和数据行是分开存储的。一张表可以有多个非聚簇索引。


___
### 43. 哈希索引和B+相比的优势和劣势？
___
### 44. MVCC知道吗？
MVCC 的全称是 Multi-Version Concurrency Control，中文是多版本并发控制。
它是一种高级的数据库并发控制技术，允许读操作和写操作在不阻塞彼此的情况下并发执行，从而极大地提升了数据库的性能和可扩展性。
它的核心思想是：不为数据行加锁，而是为每个数据行创建多个版本。

在没有 MVCC 的数据库中，为了保证数据一致性，通常使用锁机制。这会导致一些问题：
读阻塞写：一个长时间的读操作会阻塞其他事务的写操作。
写阻塞读：一个写操作会阻塞其他事务的读操作。

MVCC主要是实现两个目的：读不阻塞写：一个事务在读取数据时，另一个事务可以同时修改该数据。
写不阻塞读：一个事务在修改数据时，另一个事务可以读取该数据的旧版本。
___
