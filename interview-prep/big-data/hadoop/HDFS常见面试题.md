# HDFS基础
### 1. HDFS文件写入和读取流程
HDFS写入流程是客户端将数据分包切块，经NameNode协调后，以管道流水线方式依次写入多个DataNode副本；读取流程则是客户端从NameNode获取文件块的位置信息后，直接连接到最近的DataNode并行读取数据块，最后组合成完整文件。

___
### 2. HDFS组成架构
关于HDFS的组成架构，我可以概括为它是一个经典的主从式架构，主要包括三个核心组件和一个关键角色。

首先是最核心的主节点，NameNode。它是整个文件系统的大脑，主要负责两方面的工作。第一是管理元数据，这包括了文件的目录结构、文件被切分成哪些数据块，以及这些数据块分布在集群的什么位置。第二是协调客户端的访问，处理所有对文件的打开、读写、删除这些请求。需要强调的是，NameNode只存储和管理这些元数据信息，它本身不存储任何实际的用户数据。

然后是负责实际数据存储的从节点，DataNode。集群中会有很多个DataNode，它的职责很明确，就是根据客户端或者是NameNode的指令，来执行数据块的读写操作，并且定期向NameNode汇报自己所存储块的信息，也就是发送心跳报告，以此来保持整个集群状态的可知性。

接下来是一个非常重要的辅助角色，Secondary NameNode。这里需要特别注意，它的名字容易引起误解，它并不是NameNode的热备节点。它的核心职责是定期地帮助主NameNode合并fsimage镜像文件和edits编辑日志，防止编辑日志文件过大，从而减轻NameNode的启动压力，提升它的恢复效率。它是一个检查点节点，而不是一个备份节点。

最后是整个架构的驱动者，就是客户端。它一方面提供了各种用户访问HDFS的接口和API，另一方面在读写数据时，它会直接与DataNode进行交互，只有在获取元数据信息时才会去访问NameNode。

所以总结来说，HDFS的架构就是由一个指挥大脑NameNode、众多干活的工人DataNode、一个辅助管理的Secondary NameNode，以及发起请求的客户端共同组成的。
___
### 3. 介绍下HDFS，说下HDFS优缺点，以及使用场景


___
### 4. HDFS作用
提供一个能可靠存储海量数据的底层仓库，并支持高吞吐量的数据访问，为大数据计算奠定基础。
___
### 5. HDFS的容错机制
主要通过数据冗余和自动恢复两大策略来实现，确保集群在部分硬件故障时依然能可靠运行。
___
### 6. HDFS的存储机制
___
### 7. HDFS的副本机制
___
### 8. HDFS的常见数据格式，列式存储格式和行存储格式异同点，列式存储优点有哪些?
___
### 9. HDFS如何保证数据不丢失?
___
### 10. HDFS NameNode高可用如何实现?需要哪些角色?
___
### 11. HDFS的文件结构?
___
### 12. HDFS的默认副本数?为什么是这个数量?如果想修改副本数怎么修改?
___
### 13. 介绍下HDFS的Block
___
### 14. HDFS的块默认大小，64M和128M是在哪个版本更换的?怎么修改默认块大小?
___
### 15. HDFS的block为什么是128M?增大或减小有什么影响?
核心目的是减少寻址开销，最大化磁盘传输效率，以适应大数据高吞吐量、批量顺序读写的场景。
___
### 16. HDFS HA怎么实现?是个什么架构?
___
### 17. 导入大文件到HDFS时如何自定义分片?
___
### 18. HDFS的mapper和reducer的个数如何确定?reducer的个数依据是什么?
___
### 19. HDSF通过那个中间组件去存储数据
看来是并不需要中间件，如果是NameNode的HA要求，可能需要一个JournalNode集群作为一个中间件，将edits文件同步到SecondaryNode中。
___
### 20. HDFS跨节点怎么进行数据迁移
HDFS的跨节点数据迁移，核心目标是在不同的DataNode之间移动数据块，以实现集群的负载均衡、磁盘均衡或故障恢复。   
使用负载均衡工具，观察各节点的数据使用率与集群的平均使用率，如果相差不大则认为平衡，该工具可以自动进行DataNode之间的TCP连接与数据迁移，不需要经过客户端。    
hdfs balancer -threshold 10： 表示当每个DataNode的磁盘使用率与集群平均使用率的偏差不超过10%时，就认为集群是平衡的。
___
### 21. HDFS的数据-致性靠什么保证?
其核心可以概括为：“一次写入，追加写入”的模型、基于Pipeline的副本同步、和客户端校验机制。
HDFS通过 “写入时管道同步复制+确认机制” 保证写入一致性，通过 “校验和” 保证读取一致性，通过 “块报告和自动复制” 保证副本一致性，通过 “Edits日志和FsImage” 保证元数据一致性。这套组合拳共同确保了HDFS在分布式环境下数据的强一致性。

___
### 22. HDFS怎么保证数据安全
多副本备份，心跳检测，校验码校验
___
### 23. HDFS中向DataNode写数据失败了怎么办
HDFS的应对策略是：快速失败、自动排除故障节点、重建管道、从断点重传，并由NameNode确保副本数最终恢复。这保证了即使在写入过程中出现节点故障，也能最大限度地保证数据一致性和写入成功。

当然，故障时不会从头开始传输数据块，只能从当前数据块开始新建Pipeline传输到健康的DataNode，之前的数据块只有两副本了，就会自动开启备份，后台进行复制，直到全部数据都满足最低副本数为止。
___
### 24. Hadoop2.xHDFS快照
Hadoop 2.x 中的 HDFS 快照（Snapshot）功能是一个很重要的特性，它允许你在某个时间点为文件系统创建只读副本，常用于数据备份、防止误操作和灾难恢复

___
### 25. HDFS文件存储的方式?
___
### 26. HDFS写数据过程，写的过程中有哪些故障，分别会怎么处理?
客户端请求：客户端向NameNode发起创建文件的RPC请求。

检查与响应：NameNode检查路径、权限等，通过后在其元数据中创建文件记录，并返回一套目标DataNode列表（如DN1, DN2, DN3）给客户端。

建立管道：客户端直接与这三个DataNode建立写入管道（Pipeline）。

流水线写入：客户端将数据包（Packet）发送给管道中的第一个DataNode（DN1），DN1存储后转发给DN2，DN2存储后再转发给DN3。

反向确认：成功存储后，确认信号（Ack）沿管道反向传回（DN3 -> DN2 -> DN1 -> 客户端）。

关闭文件：所有数据写入完毕后，客户端通知NameNode关闭文件，NameNode才将文件状态置为完成。

___
### 27. NameNode存数据吗?

___
### 28. 使用NameNode的好处
除了隔离逻辑存储与物理存储，将实际存储透明化外，实现高性能的元数据访问，诸如文件打开、关闭、重命名等元数据操作速度极快，因为都是内存操作，实现了低延迟和高吞吐量的元数据服务。

NameNode管理所有的元数据，可以保证元数据的强一致性。

可扩展，NameNode管理DataNode如果扩展节点，只需要假如新的DataNode，NameNode就会自动进行管理。
___ 
### 29. HDFS中DataNode怎么存储数据的
HDFS中DataNode存储数据的方式非常直观和高效，其核心可以概括为：以块的形式，存于本地磁盘，受NameNode管理。

每个块在DataNode的本地磁盘上以一个普通的物理文件的形式存在。除了数据本身，还会存储一个校验和文件（用于验证数据完整性）和相关的元数据。

在每个DataNode节点的配置文件中，会指定一个或多个本地文件系统的目录（如 /data/1/dfs/dn, /data/2/dfs/dn）。
DataNode会将接收到的数据块存储在这些配置好的目录下。配置多个目录（通常在不同硬盘上）可以提升磁盘I/O的并行度和存储容量。

为了避免单个目录下文件过多导致性能下降，DataNode并不会将所有块文件都直接放在顶级存储目录下。
它会创建一个多层次的子目录结构，将块文件分散存储。例如，块文件 blk_1073842837 的路径可能类似于：
current / subdir0 / subdir1 / blk_1073842837
这种“化整为零”的方式极大地改善了本地文件系统的管理效率。

除了心跳检测之外：DataNode会定期（默认6小时）或启动时，向NameNode汇报它当前存储的所有数据块的列表。

在写入数据时，DataNode会计算每个数据块的校验和，并将其与数据块一起存储。
在读取数据时，DataNode会再次计算校验和并与存储的值进行比对。如果发现不匹配，说明数据已损坏，客户端会自动从其他DataNode上的副本读取。

DataNode将HDFS数据块以普通文件形式，存储在其配置的本地磁盘目录下，并通过多级子目录进行管理。它的所有行为都被动接受NameNode的指令，并通过心跳和块报告机制向NameNode汇报自己的存储状态，从而保证整个分布式存储系统的协调一致。


___
### 30. 直接将数据文件上传到HDFS的表目录中，如何在表中查询到该数据?
直接将文件上传到HDFS目录，并不意味着就能直接在SQL表中查询到它。需要执行一个关键的元数据更新操作，让表的元数据感知到新数据的存在。



___
