# Hadoop基础

1. 介绍一下Hadoop。
   Hadoop是一个开源的分布式计算框架，主要是用于处理大规模数据集的存储和计算，核心组件包括：  
- HDFS(Hadoop Distributed File System) : 分布式文件系统，将大文件，默认为128MB分块并跨多台机器存储，通过数据冗余（默认3副本）确保高容错性，主节点NameNode主节点管理元数据，从节点DataNode存储实际数据块。
- MapReduce:并行计算框架，Map代表数据分片处理，Reduce代表结果汇总，属于两个阶段，适合批处理任务。
- YARN：是资源调度系统，负责集群分配和多任务调度，支持同时运行多个应用程序，比如说Hive和Spark。

但是用户使用 Hadoop 的时候，看到的是一个文件系统，比如说要获取 hdfs/tmp/file1 的数据，引用的是一个文件路径，但是实际的数据存放在很多个不同的机器上，对用户透明。
___
2. Hadoop 的设计特点
- 适合大数据文件： 非常适合 T 级别的大文件或者一堆数据文件的存储，如果文件只有几十 GB 或者更小就不大适用；假设 HDFS 中块儿的大小为 64MB，备份数量为 3，那么一般情况下，一条元数据记录需要占用 200B 的内存，那么对于 1GB 的大文件，将占用 1GB/64MB ✕ 3 个文件块；对于 1024 个 1MB 的小文件，则占用 1024✕3 个文件块。因此，存储同等大小的文件，单个文件越小，所需要的元数据就越大，占用的内存就越大，因此适合存储大文件。另外，Spark 通常需要将数据拆分成多个小任务（逻辑分片默认为 64MB）并行处理，如果分片过大则会增加调度开销。
- 文件分布式存储：HDFS 会将一个完整的大文件平均分块存储到不同计算器上，它的意义在于读取文件时可以同时从多个主机上面读取不同区块的文件，多主机读取比单主机读取要快的多。
- 流式数据访问：一次写入多次读写，这种模式和传统文件不同，并不支持动态改变文件内容，而是要求让文件一次写入就不做变化，要变化也只能在文件末尾添加内容，通过流式的数据访问来保证高吞吐量。
- 数据靠拢：对数据进行计算时，采用的是计算像数据靠拢的方式，即选择最近的数据进行计算，减少数据在网络中的传输延迟。
- 高可靠性：HDFS 认为所有的主机都会出现问题，为了防止某个主机失效而导致读取不到该主机上面的块文件，将同一个文件副本分配到其他某几个主机上，如果一台主机失效，将迅速找另一个副本读取文件。
- 高可用性：2.0 之前，NameNode 只有一个，存在单点问题（也就是单点问题导致的整个集群都不可用，虽然 Hadoop1.0 有 secondaryNameNode，CheckPointNode， BackupNode 这些来尽量满足 HA，但是单点问题依然存在），在 Hadoop2.0 引入了新的 HA 机制，集群会同时运行两个 NameNode，一个座位活动的 NameNode（Active），一个作为备份的 NameNode（Standby）；备份的 NameNode 的命名空间与活动的 NameNode 是实时同步的，所以当活动的 NameNode 发生故障而停止服务的时候，备份的 NameNode 可以立即切换为活动状态，而不影响 HDFS 集群服务。
- 最终一致性： HDFS 是一个松散的一致性检查的模型，它主要是为了追加（append）操作而不是覆盖重写，因为覆盖重写的话可能在一次读的操作会读到其他副本不一致的数据，而追加操作中，其中一个的副本的不一致也不会导致客户端读到不一致的数据；同时 HDFS 在追加操作时采用 Lease 机制，即将块的写操作权授权给主块服务器（primary chunk server)，另外的副本称之为次块服务器（secondary chunk server），当多个客户端并发写操作时候，主块服务器缓存其写的顺序，之后联系次服务器进行追加操作。
___

3. Hadoop 不适合的场景
- 低延时的数据访问：对延时要求在毫秒级别的应用，不适合采用 HDFS，HDFS 是为高吞吐数据传输设计的，因此 HBase 更适合低延时的数据访问。
- 大量小文件也不适合，文件的元数据保存在 NameNode 的内存中，整个文件系统的文件受限于 NameNode 的内存大小，经验而谈，一个文件/目录/文件块一般占有 150 字节的元数据内存空间，如果有 100 万个文件，每个文件占用 1 个文件块，则需要大约 300M 的内存，因此上一级别的文件数量在现有的商用机器上难以支持。
- 对方读写：HDFS 采用的是追加 append-only 的方式写入数据，不支持文件任意 offset 的修改（其中，文件中的地址与内存中的地址表示不同，使用偏移量File Offset 来表示），不支持多个写入器（writer）。
___
4. Hadoop主要分为哪几个部分？他们有什么作用？  
   前面问题 1 中已经提及
___
5. Hadoop1.x 2.x 3.x 的区别。
-  1.x 版本的时候采用的还是 master/slave 模式，JobTracker 承担双重核心职责，资源管理和作业调度。这种设计导致 JobTracker 成为性能瓶颈，仅能支持约 4000 节点集群，且 MapReduce 与 HDFS 强耦合，无法扩展其他计算框架。
-  2.x 版本引入 YARN，将资源管理与作业调度进行了分离，REsourceManager 负责全局资源分配（基于容器 Container），ApplicationMaster（每个应用独立拥有）负责具体的任务的调度和监控，架构解耦后，可以支持多计算框架（MapReduce、Spark、Flink 等）运行。
-  3.x 版本延续 YARN 的分离式架构，记忆不优化资源模型--支持用户定义资源类型。3.x 提升解决 2.x 的可伸缩问题。
   
逐步升级了高可用性、存储效率。还有资源管理方面的差别。
___
6. Hadoop集群工作时启动哪些进程?它们有什么作用?
- HDFS核心进程： 
    
| 应用进程名称              | 作用                                                                                                                                                                               | 
|---------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------| 
| NameNode            | 是 HDFS 的主服务器，核心功能是管理文件系统的元数据，它处理客户端的读写请求，记录每个文件的数据块分布信息。元数据以fsimage(命名空间快照）和 edits(操作日志）形式持久化到本地磁盘。                                                                              |  
| DataNode            | 是 HDFS 的工作节点，负责存储实际数据块，默认大小为 128MB。它执行客户端或者 NameNode 调度的数据读写操作，并定期向 NameNode 发送心跳信号和块报告。                                                                                         |  
| econdaryNameNode    | 辅助名称节点），不是 NameNode 的热备，而是元数据辅助管理进程，其核心任务是定期合并 NameNode 的 edits 日志和 fsimage 文件.                                                                                                  |  
| seconaryNameNode(续) | 从 nameNode 下载 fsimage 和 edits，合并后生成新的 fsimage 并上传至 NameNode，替换旧文件。此举可以防止 edits 日志过大（避免 NameNode 重启时好时过长）。合并后的fsimage需由NameNode主动加载，SecondaryNameNode故障不会影响集群运行，但会增加NameNode恢复时间。 |  


- YARN 核心进程

| 应用进程名称            | 作用                                                                                                                                                                                                                  | 
|-------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|  
| ResourceManager   | 资源管理器<br/>是 YARN 的**全局资源管理器**， 负责整个集群的资源(CPU,内存，GPU等)分配与调度。它由两部分组成。<br/>(1) **Scheduler**，根据资源需求和队列策略（比如 FIFO）分配容器（Container）<br/> (2) ApplicationsManager（应用管理器），管理应用程序的生命周期，提交、启动、监控、终止等，协调 ApplicationMaster 的运行 | 
| NodeManager       | 节点管理器<br/>YARN的单节点资源管理者，运行在每个集群节点上。其主要职责包括：<br/>① 管理节点上的资源，如 CPU、内存等<br/>② 启动和监控容器（Container， YARN 的资源分配单位，封装了 CPU、内存等资源）；③定期向 ResourceManager 发送心跳（汇报节点资源使用情况和容器运行状态）；<br/>④ 接收 ApplicationMaster 的指令，如启动、停止任务等。   | 
| ApplicationMaster | 应用管理器<br/>每个应用程序（MapReduce、Spark）的独立管理进程。由 ResourceManager 启动，负责应用程序的具体执行：<br/>① 向ResourceManager申请资源(Container);<br/>② 协调Container的执行(如启动MapTask、ReduceTask);<br/>③ 监控任务进度（如任务失败时重新申请资源并重启）；<br/>④ 向ResourceManager汇报应用完成状态；      | 
___

7. 在集群计算的时候，什么是集群的主要瓶颈。
- 数据倾斜问题，集群计算中热点key的存在，或或者说 key 分布不均匀，某些节点或者分片就会被频繁访问，导致局部 CPU、内存或者 I/O资源耗尽，形成热点瓶颈。
- 内存不足瓶颈, 任务集群出现最多的问题都是GC 问题和 OOM 问题，集群会在夜里报警，大多数都是 GC 问题，加资源都可以解决。
- 计算资源瓶颈，例如在 Spark 集群中，如果 Driver 运行在集群模式，且所在节点资源不足，改节点可能成为整个集群的瓶颈点，影响整体计算调度与任务执行。
- 存储 I/O 与文件系统瓶颈， 文件系统的管理效率，I/O带宽、文件创建/删除等操作，尤其在分布式存储集群中，尝尝成为性能瓶颈。
- 任务调度与元数据管理瓶颈， 在大规模集群尤其是分布式存储与计算分离架构中，元数据管理（比如分片映射、节点调度、文件系统 Client 的调度等）也可能成为瓶颈。
___

8. 搭建Hadoop集群的xml文件有哪些?
（个人认为这个问题不会是面试常问的问题，怎么可能会有面试官问这种问题呢？）
不同的 Hadoop 组件有不同的配置文件：  
（·）核心配置文件（所有的 Hadoop 组件共用）core-site.xml,用来定义 Hadoop 的基础配置，比如 HDFS 的默认文件系统地址、Hadoop 的临时目录等。通常是配置 HDFS 的默认文件系统地址、Hadoop 临时目录等。  
（··）HDFS专属配置，hdfs-site.xml，配置HDFS（Hadoop 分布式文件系统）的相关参数，如 NameNode 数据存储目录、副本数、高可用配置等等。  
（···）YARN 配置文件，yarn-site.xml，配置YARN 的资源管理相关参数，比如说 ResourceManager 地址、NodeManager 配置、容器资源分配等。  
（····）MapReduce配置文件，计算框架的，mapred-site.xml,配置计算框架的运行模式。  

___
9. Hadoop的checkpoint流程。

___
10. Hadoop的默认块大小是多少?为什么要设置这么大?

___
11. Block划分的原因.

___
12. Hadoop常见的压缩算法?

___
13. Hadoop作业提交到YARN的流程?

___
14. Hadoop的Combiner的作用.

___
15. Hadoop序列化和反序列化.

___
16. Hadoop的运行模式.

___
17. Hadoop小文件处理问题.

___
18. Hadoop为什么要从2.x升级到3.x?

___
19. Hadoop的优缺点。

___